We design several algorithms representing evaluation processes of different complexity, ranging from basic
environments based on a predetermined number of features to complex structures involving alternatives
defined through decision trees whose number of nodes is determined by the cardinality of the respective
power sets. The sequential structure of these evaluation processes builds on the information retrieval behavior
of users in online search environments. The algorithms generate two strings of data, namely, numerical
evaluations determining the retrieval behavior of users and the subsequent choices made by the latter. The
way the output obtained from the algorithms is inputted within the vectors summarizing the complexity of the
evaluation processes conditions the capacity of machine learning techniques to categorize them correctly. The
main purpose of the research is to illustrate numerically two main results. First, machine learning techniques
categorize processes correctly even if their characteristic features are presented in a way that prevents their
identification using standard statistical techniques. Second, the accuracy of the categorization capacities of
these techniques can be substantially enhanced by describing the retrieval processes in the way required to
implement standard statistical analyses. We perform a battery of tests using machine learning techniques to
demonstrate and analyze these results. Their applicability to classification and prediction problems in medical
environments, particularly those constrained by the quality of the data available, is emphasized.. Introduction
The current study builds on the online information retrieval pro-
esses of decision makers (DMs) analyzed by decision theorists and
anagement scholars. The raw data available describing the retrieval
ehavior of DMs provides information on the pages clicked and the
ubsequent click through rates (CTRs) generated through the different
ueries (Chitika, 2013; Dean, 2019). This information, essential to
nderstand the potential retrieval patterns of DMs, is generally used to
ighlight the importance of ranking positioning within the results dis-
layed by a search engine (Epstein & Robertson, 2015; Pan et al., 2007).
esearchers dealing with decision theoretical models have focused on
xtrapolating the utility functions leading to this type of observed
ehavior (Basu, 2018; Victorelli, Dos Reis, Hornung, & Prado, 2020).
owever, as intuition suggests, the behavioral patterns emerging from
he data may be generated by different sequential information retrieval
trategies of varying complexity.
An important observation is due here. The main empirical studies
escribing the retrieval behavior of DMs do not provide any details
egarding how the data has been inputted before being analyzed (Chi-
ika, 2013; Dean, 2019). That is, the order of the entries composing the
‚àó Corresponding author.
E-mail addresses: debora.dicaprio@unitn.it (D. Di Caprio), fsantosarteaga@unibz.it (F.J. Santos-Arteaga).
1 Both authored the manuscript to which they have contributed equally.
data vectors, namely, the alternatives clicked from the page of results
displayed by the engine, is not relevant when analyzing variables that
define averages across observations such as the CTRs. As a result,
this information is not reported when considering research papers that
analyze trends in the information retrieval behavior of DMs performing
online queries (Li, Duan, Zheng, Wang, & Wang, 2020). However, it
is generally understood that this information is extremely important
when considering standard statistical analyses. This is the case since the
order of the elements composing the entries defining the data vectors
conditions the results derived from the subsequent regressions.
The main objective of the current research is to analyze the iden-
tification capacities displayed by machine learning techniques when
categorizing evaluation patterns of different complexity. We illustrate
how the identification capacities of these techniques are determined,
and can be enhanced, by the way the features are ordered within
the vectors defining the alternatives. The novel characteristics of the
proposed approach can be summarized as followsttps://doi.org/10.1016/j.mlwa.2021.100196
eceived 29 May 2021; Received in revised form 20 October 2021; Accepted 24 O
vailable online 6 November 2021
666-8270/¬© 2021 Published by Elsevier Ltd. This is an open access article under
http://creativecommons.org/licenses/by-nc-nd/4.0/).ctober 2021
the CC BY-NC-ND license
D. Di Caprio and F.J. Santos-Arteaga Machine Learning with Applications 7 (2022) 100196Fig. 1. Annual organic CTRs for international desktop searches.
Source: Advanced Web Ranking (2021).1. We define sequential evaluation processes of different complex-
ity whose structure builds on the information retrieval behavior
of users in online search environments.
2. We illustrate how these evaluation processes can be simulated
by algorithms of different complexity.
3. We demonstrate numerically how the way the output obtained
from the algorithms is inputted within the vectors summarizing
the evaluation processes conditions the categorization capacity
of machine learning techniques. This result is illustrated using a
generic numerical example as well as calibrating the behavior of
DMs to the CTRs observed in real life evaluation environments.
4. We highlight the superior categorization capacities of machine
learning techniques relative to standard statistical analyses, par-
ticularly when considering misprints or errors in the matrices
defining the input or independent variables.
This last quality is extremely important in areas such as medicine,
where a general distrust in artificial intelligence and machine learn-
ing techniques is leaning the profession towards the use of standard
statistical tests (Bae et al., 2020; Lancet, 2021; Wynants et al., 2020).
The capacity of machine learning techniques to overcome the potential
identification problems arising from the existence of data misprints
should provide a powerful argument in support of their use.
1.1. Analyzing the information retrieval behavior of DMs
The reference framework on which we build the algorithms de-
signed to test the identification capacities of different machine learning
techniques is that of online information retrieval. This choice is justified
by the fact that algorithms based on retrieval patterns corresponding
to users exhibiting different degrees of behavioral complexity can be
simulated and framed within an intuitive presentation framework.
The information assimilation capacities of DMs constitute one of the
main research topics in decision theory and have been analyzed from
a variety of academic perspectives, ranging from operations research
to psychology (Schwartz, 2015; Tavana, Caprio, & Santos-Arteaga,
2017). In this regard, the availability of data describing the CTRs that
result from the searches performed by DMs within an unmonitored
environment provides a substantial amount of intuition regarding the
complexity of their retrieval behavior.
Fig. 1 presents the annual organic CTRs derived from international
desktop searches over the last five years. The observed CTRs are consis-
tent both across countries and through time, with users concentrating
their searches on the initial alternatives composing the first page of
results provided by search engines. This behavior validates the results2
Fig. 2. Decision tree describing the evaluation of two alternatives.
Fig. 3. Code of an ordered algorithm where DMs consider evaluating two alternatives.
obtained in multiple empirical experimental studies illustrating the
sequential evaluation processes followed by DMs when retrieving in-
formation form the ranking of alternatives provided by a search engine
(Epstein & Robertson, 2015; Lewandowski & Kammerer, 2020).
Consider now the standard definition of CTR
CTR of alternative ùëñ
=
Number of users clicking on the link to alternative ùëñ
Number of users performing a search (1)
Fig. 4. Initial section of the decision tree describing the search for two satisfying alternatives.
Given this definition and the conditioning of the sequential evalua-
ion processes on the ranking of the alternatives, two main completely
ifferent types of DMs can be assumed to generate the CTRs observed.
n one hand, DMs could lack a structured evaluation process and
ase their behavior on a predetermined set of acceptance probabilities
efined for each of the alternatives composing the ranking. On the
ther hand, DMs could follow a completely structured search process
iming to observe the largest potential number of alternatives satisfying
given set of requisites determining their acceptance probabilities.
n other words, the value of the CTRs does not reflect whether DMs
ollow highly elaborated evaluation patterns or implement heuristic
echanisms.
When designing algorithms to simulate the retrieval behavior of
Ms, each run can be assumed to represent a search query. As a result,
he law of large numbers implies that a trivial algorithm defining ten
ndependent realizations from ten random variables leads to a behavior
dentical to the one observed in the data. The algorithm only requires
set of acceptance thresholds determined by the corresponding CTRs.
t the same time, a complex algorithm accounting for each and every
otential combination that may be followed by a user as he retrieves
nformation leads to the same result. In this case, the user considers
valuating the whole set of alternatives composing the first page of
esults based on a set of predetermined acceptance thresholds.
We elaborate on these scenarios and their consequences relative to
he capacity of machine learning techniques to differentiate between
oth types of DMs through the next section.
. Contribution
Consider the case where a DM evaluates the first two alternatives
rom a list and stops afterwards. The DM selects the alternatives per-
orming above a given threshold defined by a predetermined selection
riterion. This scenario differs substantially from one where the DM sets
ut to find two alternatives from a given list satisfying a given selection
riterion. In this case, the alternatives are not necessarily the first two
ut can be located anywhere within the list.
The differences in retrieval abilities between both scenarios and
he complexity of the resulting algorithms designed to simulate both
equential processes are substantial.
‚Ä¢ In the first case, we can define a simple decision tree consisting
of three decision nodes that determine the retrieval behavior
of DMs based on two potential realizations per node and the
corresponding threshold values. Fig. 2 illustrates a binary decision
tree representing this type of evaluation scenario, while Fig. 3
presents a basic algorithm describing the resulting information
retrieval behavior. The continuous lines within the tree represent
realizations from alternatives located above the predetermined
threshold, while the dotted ones refer to evaluations underper-
forming relative to the threshold value. The code defined in Fig. 3
describes this retrieval process, imposing a threshold of 0.5 for
stochastic realizations of the evaluations uniformly distributed
within the interval [0, 1]. A more detailed description of the
retrieval process coded in Fig. 3 will be provided in Fig. 6 within
the next section.3
‚Ä¢ In the second case, the information retrieval behavior is con-
siderably more complex, since DMs must consider the potential
evaluations arising from the whole set of alternatives through the
retrieval process. If the list consists of ten alternatives, as is the
case when retrieving information from an online search engine,
the number of decision nodes composing the subsequent decision
tree equals 55. Fig. 4 illustrates the initial section of a decision
tree describing the information retrieval process of a DM who
aims at finding two satisfying alternatives from a given list. A
more detailed description of this type of retrieval process will be
provided in Fig. 7 within the next section.
The importance of feature positioning within the vectors describing
the retrieval processes of DMs becomes evident now. Clearly, if we in-
put the alternatives clicked according to the position in which they are
located within the ranking, the behavior of DMs can be differentiated
by machine learning techniques simply based on positioning. That is,
the way the features characterizing the retrieval processes are inputted
can be used to enhance the categorization capacity of machine learning
techniques. The main contribution of the current paper consists in
illustrating the extent of this enhancement when dealing with different
types of retrieval scenarios characterized by the assimilation capacities
of DMs and the number of alternatives defining the search.
2.1. A numerical illustration
Five evaluation processes derived from a retrieval scenario account-
ing for six alternatives with a threshold value of 0.50 have been
described within the first set of columns of Table 1. Note that each
column vector describes the evaluation process of a DM and has been
divided in two distinct sections. The upper one, denoted ‚Äòinitial eval-
uation‚Äô, presents the realizations observed for each of the alternatives
composing the ranking, which are drawn from a uniform distribution
defined on [0, 1]. The lower section, denoted ‚Äòthreshold satisfying al-
ternatives‚Äô, identifies the alternatives clicked by the DMs as determined
by their realizations and the value of the threshold. The corresponding
MATLAB code is provided in Figure A1 within Appendix A section.
In this case, denoted ‚Äòordered evaluation process‚Äô, the alternatives
satisfying the threshold requirement have been reported according to
the position where they are located within the first ten entries of
the vector defining the information retrieval process. The remaining
entries of the vector have been defined by zeros. Fig. 5 describes the
retrieval framework corresponding to an ordered evaluation process
accounting for two alternatives. The retrieval of information is defined
by two independent and unrelated evaluations, i.e., ùë•1 and ùë•2. That is,
he evaluations obtained when observing the first alternative, do not
ondition the inputs of the subsequent binary nodes. The final nodes
esulting from the retrieval process correspond to those derived from
ach binary node for each alternative composing the ranking.
The second set of columns within Table 1 represents a binary
valuation setting where the alternatives satisfying the threshold re-
uirement have been reported in the initial entries composing the
ower section of the vector. Consequently, this case has been denoted
Fig. 5. Retrieval framework of the ordered evaluation process with two alternatives.
‚Äògrouped evaluation process‚Äô. The corresponding algorithm is described
in Figure A2 within Appendix A. Fig. 6 illustrates the basic structure of
a grouped evaluation process accounting for two alternatives. That is, a
binary tree based on the two evaluations defining the retrieval process,
ùë•1 and ùë•2. Note how the realizations of the previous evaluations deter-
ine the entries inputted in the vectors. These interactions define an
nterrelated evaluation framework that requires enhanced assimilation
apacities on the side of DMs and the design of a more complex retrieval
lgorithm.
The third set of columns within Table 1 describes five alternatives
rom the latter, increasingly complex, ‚Äòcomplete evaluation process‚Äô. In
his case, DMs aim at finding six alternatives satisfying a predetermined
riterion out of a total of ten. The code of the corresponding algorithm
an be found in Figure A3 within Appendix A. Note how the alter-
atives satisfying the threshold requirement have also been grouped4
within the initial entries composing the lower section of the vector.
The complete evaluation process requires introducing an even more
complex set of relations than those described in the grouped setting.
However, both retrieval frameworks converge when considering the
whole set of alternatives. The retrieval structure described in Fig. 7 is
more elaborated than the binary decision tree presented in Fig. 6. That
is, the grouped scenario is constrained by a predetermined number of
evaluations that binds independently of the value of the realizations
observed. The complete evaluation process requires defining a more
complex retrieval setting since DMs may have to proceed through the
whole ranking of alternatives. i.e., ùë•ùëñ with ùëñ = 1,‚Ä¶ , 10.
Fig. 8 complements these results by illustrating the retrieval patterns
obtained from 2000 queries per evaluation process when DMs aim to
observe ten satisfying alternatives. The figure follows from pairing the
value of the initial evaluations with the threshold satisfying alternatives
clicked per search query. That is, the data illustrated consist of two
column vectors, one describing the evaluations performed by the DMs
and the other representing the subsequent alternatives clicked. As was
the case in Table 1, each evaluation process has been assigned a
threshold value of 0.5 per alternative. It therefore follows that the
ordered setting only assigns a value of zero to realizations located
below 0.5.
On the other hand, the grouped and complete processes only display
this feature for the first alternative composing the ranking. This is
the case since, whenever the first alternative is clicked, the corre-
sponding entry of the initial evaluation vector must be associated
with a realization higher than 0.5. However, when the first alternative
is not clicked, the first entry of the vector describing the threshold
satisfying alternatives corresponds to a number different from one.
This feature applies to the whole set of alternatives and explains the
different patterns observed in the grouped and complete processes
when compared to the ordered one. It also highlights how the order
in which the alternatives are inputted may determine the capacity of
any categorization technique to identify the corresponding retrieval
patterns.
Two observations are due. First, when considering a scenario based
on two satisfying alternatives, the value of the alternatives clicked
suffices to identify those DMs implementing a complete evaluation
processes. This is the case even if the information is placed within
the initial entries of the vector describing the retrieval processes. That
is, the two initial entries of the vectors defining ordered and grouped
retrieval processes will be composed by zeros, ones, and twos. On the
other hand, the two initial entries of the vectors describing complete
D. Di Caprio and F.J. Santos-Arteaga Machine Learning with Applications 7 (2022) 100196Fig. 6. Retrieval framework of the grouped evaluation process with two alternatives.Fig. 7. Initial section of the complete evaluation process with two alternatives.retrieval processes can display any number up to ten. This feature
suffices on its own to differentiate between both process categories.
Second, the ability of machine learning techniques to differentiate
between processes vanishes as we increase the number of alternatives
defining the search and approach the limit value of ten.
Given these numerical simulations, it can now be intuitively under-
stood how
‚Ä¢ the simplest ordered algorithm, where DMs perform ten indepen-
dent evaluations, with a predetermined threshold value defined
for each alternative, and5
‚Ä¢ the complex complete algorithm, where DMs aim at evaluating
the ten alternatives delivered by a search engine within its first
page of results
lead to the same stochastic retrieval structure and deliver identical
CTRs.
3. Identification results
In computer science terminology, classification problems consist of
a set of predictors, that is, features describing the different alternatives,
defined via n-dimensional vectors and an outcome per alternative,
namely, the class to which the alternative belongs.
Fig. 8. Retrieval profiles generated by the different evaluation processes within the
ten alternatives scenario.
techniques assess the features of each alternative together with its
class and learn from them so that whenever an alternative is observed,
the class to which it belongs can be predicted. Clearly, in the current
setting, the alternatives refer to the retrieval processes defined by the
different types of DMs ‚Äì who determine the classes ‚Äì when evaluating
the information provided by a search engine.
Table 2 describes the number of seconds required for the code to
run and generate the output describing the evaluation profiles defined
by the different types of DMs. As illustrated in Table 1, the algorithms
generate column vectors composed by 20 rows to describe the retrieval
process triggered by a search query. The first half of the vector cor-
responds to the value of the realizations observed by DMs while the
second half describes the pages being clicked. Each scenario simulated
within Table 2 generates 1,000,000 queries, constituting the columns
of the corresponding matrices. The time required to run the algorithms
reflects the complexity of the retrieval structures being analyzed.
The differences arising across the scenarios simulated and within
them are indeed substantial. When considering two satisfying alter-
natives, a noticeable difference in processing time arises between the
ordered and grouped algorithms and the complete one, whose relative
complexity becomes already evident. These differences are exacerbated
when accounting for six alternatives and become even larger when
ten alternatives are considered. Note how, in this latter scenario, the
grouped and complete scenario converge in their processing times.
As stated before, both algorithms share an identical binary retrieval
structure when evaluating the whole set of alternatives available. The
grouped evaluation process requires DMs to group the pages clicked
within the initial entries of the lower half of the vector describing their
retrieval behavior per search query. This feature imposes additional
cognitive requirements on the DMs, whose complexity increases as
the binary tree progressively accounts for all the potential alternatives
composing the initial page of results.
Through this section, we illustrate how machine learning techniques
can generally differentiate among the evaluation scenarios generated
by the different types of DMs. At the same time, displaying the alter-
natives clicked according to their position within the upper section of a
6
the vector defining the retrieval process improves the identification ca-
pabilities of these techniques substantially. These results are presented
in Table 3, where several machine learning techniques have been ap-
plied to identify the DMs implementing a complete evaluation scenario
relative to the ordered and grouped ones. That is, the ORD entries
of the table refer to categorization problems involving ordered and
complete retrieval processes, while the GRP entries focus on grouped
and complete processes. A total of 2000 queries have been simulated
per retrieval processes within each evaluation scenario. The numerical
results obtained remain unchanged when increasing or decreasing the
number of queries simulated within a reasonable range.
The basic setting accounts for retrieval processes defined exclusively
by the lower section of the evaluation vectors. Note how adding the
upper section of the vectors, namely, the enhanced feature setting,
improves slightly the categorization capacity of the techniques. How-
ever, it is the distribution of alternatives within the lower section of
the vector according to the position reported within the upper one
what increases their identification capacities. This quality is particu-
larly evident in evaluation scenarios consisting of ten alternatives. As
already stated, the algorithms presented in Figures A2 and A3 within
Appendix A coincide when considering ten alternatives, distorting the
identification capacity of the techniques considerably.
A technical note is due. The program applies a default 5-fold cross-
validation procedure to protect against overfitting and estimate the
predictive accuracy of the models. That is, the program partitions the
data set in 5 folds. For each validation fold, the program trains a model
using observations not contained in the validation fold and assesses
its performance using the data from the validation-fold. Finally, it
calculates the average validation error over all folds.
Table 4 displays the confusion matrices corresponding to the best
performing techniques within each scenario analyzed in Table 3. Class
1 corresponds to the complete evaluation process while Class 2 refers
to either the ordered or grouped one. Clearly, machine learning tech-
niques can correctly categorize the evaluation processes in scenarios
with two and six alternatives, while facing difficulties when considering
ten alternatives. In this latter case, the improvement obtained when
providing the whole vector of features, including the realizations com-
posing its upper section, is marginal. On the other hand, when the lower
section of the vectors describes the alternatives clicked according to the
order displayed within the upper section, the categorization capacity of
these techniques increases substantially.
These results are corroborated by the value of the area under
the receiver operating characteristic (ROC) curve and through two
additional accuracy tests described in Table 5. The F-measure is defined
as the harmonic mean of precision and recall, that is, given the matrix
entries described in Table 4(a)
F-measure = ùëáùëÉ
ùëáùëÉ + 0.5 (ùêπùëÉ + ùêπùëÅ)
(2)
Its highest value is 1, indicating perfect precision and recall, and the
lowest is 0, if either precision or recall equal zero.
The Kappa statistic was originally proposed as a chance-corrected
version of accuracy, and is defined as follows
Kappa statistic =
2 (ùëáùëÉ √ó ùëáùëÅ ‚àí ùêπùëÅ √ó ùêπùëÉ )
(ùëáùëÉ + ùêπùëÉ ) √ó (ùêπùëÉ + ùëáùëÅ) + (ùëáùëÉ + ùêπùëÅ) √ó (ùêπùëÅ + ùëáùëÅ)
(3)
Its worst value is given by ‚àí1, describing a perfectly wrong predic-
ion, while the best one equals 1, corresponding to a perfect classifica-
ion.
For completeness, we apply the retrieval scenario with ten alterna-
ives to the average of the CTRs defined over the period described in
ig. 1. The average CTRs together with those generated by the ordered
nd complete algorithms for a total of 1,000,000 simulated queries are
D. Di Caprio and F.J. Santos-Arteaga Machine Learning with Applications 7 (2022) 100196Table 3
Pattern recognition capacities across machine learning techniques.Table 4
Confusion matrices across evaluation scenarios.presented in Table 6. Clearly, both retrieval processes are able to mimic
the CTR behavior of users observed empirically.7
The accuracy scores achieved by the different machine learning
techniques together with the corresponding confusion matrices and
additional performance tests are summarized in Tables 7, 8 and 9, re-
spectively. As was the case with the results presented in Table 3, a total
of 2000 queries have been simulated per retrieval process within the
current evaluation scenario. We can observe how feature positioning
increases the capacity of these techniques to validate whether DMs
‚Ä¢ perform a simple search, based on independent thresholds equat-
ing the values of the corresponding CTRs, or
‚Ä¢ consider a complete sequential structure, where the realizations
observed determine the subsequent retrieval paths,
hen retrieving information from the alternatives delivered by a search
ngine within its first page of results.
We conclude by noting that machine learning techniques can be
revented from distinguishing among DMs by imposing an acceptance
hreshold sufficiently close to 100%, which generates indistinguishable
atterns across the three evaluation processes. That is, the capacity
f machine learning techniques to categorize DMs depends on the
hreshold values defining their retrieval behavior. We have selected
neutral value of 1‚àï2 within the uniform [0, 1] framework analyzed,
hough strong biases towards any end of the density domain would
ffect the categorization abilities of these techniques. s
8
Table 8
Confusion matrices and empirical CTRs.
4. Hyperparameter optimization
The selection of the hyperparameters defining each machine learn-
ing technique constitutes one of the main determinants of their accu-
racy. Thus, those parameters that can be modified within each model
can be tested to evaluate its performance. The parameters are deter-
mined by the type of model being considered within each family of
classification techniques described in Tables 3 and 7, namely, decision
trees, discriminant analysis, na√Øve Bayes classifiers, support vector ma-
chines (SVM), nearest neighbor and ensemble classifiers. For instance,
given the accuracy displayed by the Fine Gaussian SVM in the enhanced
ordered scenario with two alternatives, we optimize the hyperparam-
eters within the SVM family of techniques. As illustrated in Table 5,
a Gaussian Kernel displays the highest efficiency when optimizing the
hyperparameters, leading to an almost identical accuracy as the original
classifier.2
MATLAB tunes the hyperparameters though Bayesian optimization.
The goal of the optimization problem is to find a set of hyperparameter
values that minimize the classification error of the model. The program
maximizes the expected improvement of the objective function to
2 A complete description of all the optimizable hyperparameters, their
otential values and ranges can be found at https://it.mathworks.com/help/
tats/hyperparameter-optimization-in-classification-learner-app.html.Table 7
Table 9
Pattern recognition capacities and empirical CTRs: enhanced performance analyses.
Alternatives Ten (empirical CTRs)
Setting Basic Enhanced
Scenario GRP ORD GRP ORD
Most accurate technique (Table 7) Cubic KNN Boosted trees Bagged trees Boosted trees
Area under ROC curve 0.50 0.80 0.49 0.79
F-measure 0.664 0.559 0.507 0.580
Kappa statistic 0.006 0.385 ‚àí0.016 0.373
Hyperparameter (HP) Spearman distance Bag ensemble Logit boost ensemble Bag ensemble
HP accuracy 50.0% 69.0% 50.8% 68.7%
HP training time (s) 43.512 122.94 149.58 97.976Fig. 9. Hyperparameter optimization and classification errors in evaluation scenarios with two alternatives.l
etermine the next set of hyperparameter values that will be tried.3
ach iteration corresponds to a combination of hyperparameter values.
he default number of iterations is 30. The optimized hyperparameters
or each of the evaluation scenarios analyzed are described in Tables 5
nd 9, together with their corresponding accuracies and the training
ime required to perform the 30 iterations.
As can be observed through Figs. 9 to 12, the tuning process
elivers two different sets of hyperparameters, namely, best point and
inimum error. This difference follows from the fact that the best
oints selected do not necessarily deliver the minimum classification
rror within the 30 iterations performed. Indeed, the program selects
3 The default acquisition function is denoted expected improvement
er second plus. Further details describing the optimization problem
mplemented are given at https://it.mathworks.com/help/stats/bayesian-
ptimization-algorithm.html#bvbjtxi. b
9
the hyperparameter values that minimize an upper confidence interval
of the classification error objective model.4
We consider the optimization of hyperparameters as a validation
scheme and focus on analyzing the error minimization processes de-
fined through the different iterations displayed in Figs. 9 to 12. The
analysis allows us to validate the main results described in the previous
sections and emphasize the difficulties faced by the different techniques
when dealing with the scenarios composed by ten alternatives. Note, in
particular, the substantially larger classification errors exhibited by the
optimization processes within the GRP scenarios depicted in Figs. 11
and 12 relative to those presented in Figs. 9 and 10. Further technical
details describing the optimized hyperparameters are provided within
each figure.
4 Additional details regarding the definition of the best points se-
ected by the program can be found at https://it.mathworks.com/help/stats/
ayesianoptimization.bestpoint.html.
D. Di Caprio and F.J. Santos-Arteaga Machine Learning with Applications 7 (2022) 100196Fig. 10. Hyperparameter optimization and classification errors in evaluation scenarios with six alternatives.Fig. 11. Hyperparameter optimization and classification errors in evaluation scenarios with ten alternatives.
Fig. 12. Hyperparameter optimization and classification errors in evaluation scenarios with ten empirical CTRs alternatives.Table 10
Statistical analysis of the relationship between evaluation processes.
Scenario Two Six Ten Ten (empirical CTRs)
Setting ORD GRP ORD GRP ORD GRP ORD GRP
h 1 1 1 1 0 0 0 0
p-value 0 0 0 0 0.8433 0.8771 0.3469 0.8843
ùë°-statistic 49.473 46.713 65.405 64.176 ‚àí0.198 0.155 0.941 ‚àí0.146
Standard deviation 1.2456 1.3327 3.1723 3.2201 5.2582 3.7499 1.4433 1.3116
Degrees of freedom: 19,999 in all settings.. Machine learning versus statistical analyses
We analyze the results obtained when performing a standard sta-
istical t-test to differentiate among evaluation processes. We focus on
he relationship existing between the strings of values describing the
hreshold satisfying alternatives clicked. This is done by merging the
ower section of the evaluation vectors into column vectors describing
he pages clicked per evaluation process and computing the t-value of
he corresponding paired series.
The vectors describing each evaluation process are composed by a
otal of 20,000 rows. As illustrated in Table 1, each search query is
epresented by a matrix column composed by ten evaluations, with
he resulting pages clicked determining the values inputted in the ten
ower rows defining the query. That is, each query is composed by
0 potential clicks. Given the 2000 queries simulated per evaluation
rocess within each scenario, we generate column vectors of 20,000
ows and compute the differences in means using a paired-sample t-
est statistic. For instance, the null hypothesis states that the pairwise
ifference between the ordered and complete evaluation processes
ollows a normal distribution with zero mean and unknown variance.
value of h = 1 indicates that the t-test rejects the null hypothesis at
he 5% significance level.11Table 10 summarizes the main results obtained from these pairwise
comparisons. The statistic does not identify a relationship between
evaluation processes when considering less than ten alternatives. That
is, the statistical test suffices to validate the fact that the strings of clicks
follow from different evaluation processes. The variability displayed
within the lower section of the evaluation vectors suffices to identify
the differences between processes. However, the statistic is unable to
validate the fact that the retrieval processes are indeed different when
considering ten alternatives. This is the case for all the evaluation
scenarios accounting for ten alternatives.
Thus, standard statistics correctly identify the different processes
when analyzing relatively simple retrieval scenarios. However, these
techniques underperform as the complexity of the evaluation processes
increases. On the other hand, machine learning techniques correctly
differentiate between the ordered and complete evaluation processes
in the scenario with ten alternatives. The capacity of these latter tech-
niques to consider the whole vector of features when categorizing the
alternatives confers them with an important advantage over standard
statistical analyses, which are highly dependent on the quality of the
data defining the corresponding independent variables.
Regarding the immediate applicability of these results, we must
highlight the fact that, despite the reticence of physicians, machine
D. Di Caprio and F.J. Santos-Arteaga Machine Learning with Applications 7 (2022) 100196learning techniques remain a consistent reference tool in medical en-
vironments (Massie et al., 2020; Siga et al., 2020). The capacity of
machine learning techniques to deliver consistent results when deal-
ing with potential data misprints is particularly relevant when con-
sidering the coordination problems faced by hospitals in emergency
situations or when comparing and merging databases across differ-
ent sections (Arora, Banerjee, & Narasu, 2020; Rasheed et al., 2020;
Vaishya, Javaid, Khan, & Haleem, 2020). This is an important problem
among hospitals located in developing countries, where the quality of
the data retrieved is generally lower, limiting their identification and
extrapolation capacities. Thus, the implementation of machine learning
techniques combined, for instance, with mathematical optimization
methods can provide a consistent solution to an endemic suboptimal
situation affecting institutions facing data quality constraints (Revuelta
et al., 2021).
6. Conclusion
Machine learning techniques consider each observation as a set of
predictor values ordered within a vector together with the class to
which the observation belongs. We have illustrated how these tech-
niques are able to categorize DMs correctly even when failing to convey
important information regarding the sequential retrieval behavior char-
acterizing the evaluation processes. In this regard, inputting the pages
clicked so as to represent the order of evaluation enhances substantially
the categorization capacity of these techniques. This quality constitutes
an important advantage over standard statistical methods, particularly
when the data is organized incorrectly or sparsely.
We have indeed concluded by performing a statistical analysis of the
relationship between the strings of data describing the pages clicked by
DMs within each evaluation scenario. We have run t-tests to validate
the capacity of standard statistical techniques to recognize whether the
clicks are derived from the same type of evaluation process. The results
obtained confirmed the intuition developed through the paper. That is,
the processes compared within the evaluation scenarios consisting of
two and six alternatives lack any relationship at the 5% significance
level. On the other hand, when considering the scenario with ten
alternatives, the test validated the existence of a relationship between
the retrieval processes compared. In other words, the t-test concluded
that the ordered evaluation process was equivalent to the complete one,
a drawback that machine learning techniques manage to overcome.
Note that these results should not be interpreted as a call to pri-
oritize the implementation of machine learning techniques over stan-
dard statistical analyses, but as an illustration of the complementari-
ties existing between both types of methods, particularly in scenarios
constrained by the low quality of the data being analyzed.